from clearml import Task
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, accuracy_score
import joblib

# Init ClearML Task
task = Task.init(project_name="Fake News Detection", task_name="Pipeline Step 4 - Hyperparameter Tuning")
args = {
    'dataset_task_id': '67f36284cc4644f5bbe4e77ca1da6933'  # Step 2 Task ID
}
task.connect(args)

# Load dataset artifacts
dataset_task = Task.get_task(task_id=args['dataset_task_id'])
X_train = dataset_task.artifacts['X_train'].get()
y_train = dataset_task.artifacts['y_train'].get().to_numpy().copy()



logger = task.get_logger()

def run_grid_search(name, model, param_grid):
    print(f"Tuning {name}...")
    grid = GridSearchCV(model, param_grid, cv=3, scoring="accuracy", verbose=1, n_jobs=-1)
    grid.fit(X_train, y_train)

    best_model = grid.best_estimator_
    best_params = grid.best_params_
    best_score = grid.best_score_

    # Save and upload model
    model_filename = f"{name}_best_model.pkl"
    joblib.dump(best_model, model_filename)
    task.upload_artifact(model_filename.split(".")[0], model_filename)

    logger.report_scalar(title=name, series="best_accuracy", value=best_score, iteration=0)

    print(f"Best Params for {name}: {best_params}")
    print(f"Best Accuracy: {round(best_score, 4)}")

    return name, best_params, best_score

# Expanded parameter grids
param_grid_pa = {
    "C": [0.001, 0.01, 0.1, 1.0, 5.0, 10.0],
    "max_iter": [100, 500, 1000]
}
param_grid_svm = {
    "C": [0.1, 1, 5, 10, 50],
    "kernel": ["linear", "rbf"],
    "gamma": ["scale", "auto"]
}
param_grid_xgb = {
    "n_estimators": [100, 200, 300],
    "max_depth": [3, 5, 7],
    "learning_rate": [0.01, 0.05, 0.1],
    "subsample": [0.8, 1.0]
}

results = []
results.append(run_grid_search("PassiveAggressive", PassiveAggressiveClassifier(), param_grid_pa))
results.append(run_grid_search("SVM", SVC(), param_grid_svm))
results.append(run_grid_search("XGBoost", XGBClassifier(use_label_encoder=False, eval_metric='logloss'), param_grid_xgb))

# Summary print
print("\nSummary:")
for name, params, score in results:
    print(f"{name}:\nBest Params: {params}\nBest Score: {round(score, 4)}\n")

task.close()
